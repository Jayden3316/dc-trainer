experiment_name: "generation_baseline"
seed: 42
train_metadata_path: "experiments/data/generation_dataset/metadata.json"
val_metadata_path: "experiments/data/generation_dataset/metadata.json"
image_base_dir: "experiments/data/generation_dataset"

dataset_config:
  width: 200
  height: 80
  width_divisor: 4
  width_bias: 0

model_config:
  task_type: "generation"
  encoder_type: "asymmetric_convnext"
  encoder_config:
    dims: [64, 128, 256, 512]
    stage_block_counts: [2, 2, 6, 2]
  
  projector_type: "linear"
  
  sequence_model_type: "transformer_encoder"
  sequence_model_config:
    d_model: 256
    n_layers: 4
    d_head: 64
    
  head_type: "ctc"
  head_config:
    d_model: 256
    d_vocab: 62
  
  d_model: 256
  d_vocab: 62
  loss_type: "ctc"

training_config:
  batch_size: 32
  epochs: 50
  learning_rate: 0.0001
  optimizer_type: "adamw"
  checkpoint_dir: "checkpoints"
