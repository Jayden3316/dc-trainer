experiment_name: "classification_baseline"
seed: 42
train_metadata_path: "dataset_train/dataset/metadata.json"
val_metadata_path: "dataset_val/dataset/metadata.json"
# image_base_dir: "dataset_train/dataset" # necessary only if train_metadata_path and val_metadata_path are not provided

dataset_config:
  # Dimensions to generate/resize images to
  width: 200
  height: 80
  width_divisor: 4 # Requirement for some encoders like ConvNext
  width_bias: 0
  resize_mode: "fixed"
  image_ext: "png"
  
  # Font & Noise settings (used for generation) For training, these are saved in config, but are not useful for the model
  max_fonts_per_family: 1 
  random_capitalize: False
  noise_bg_density: 0
  add_noise_dots: False
  add_noise_curve: False
  extra_spacing: 0
  spacing_jitter: 0
  word_space_probability: 0
  word_offset_dx: 0.0

model_config:
  pipeline_type: "standard_classification" # "standard_classification" or "sequence_classification"
  task_type: "classification" # "classification" or "generation"
  
  # --- 1. Encoder (Backbone) ---
  encoder_type: "resnet" # Recommended for classification
  encoder_config:
    # ResNet dimensions per stage
    dims: [8, 16, 32, 64] 
    stage_block_counts: [1, 1, 3, 1]
    strides: [(2, 2), (2, 2), (2, 2), (2, 2)]
    
  # --- 2. Adapter (Spatial -> Vector) ---
  adapter_type: "flatten" # "flatten", "global_pool", or "vertical_feature"
  adapter_config:
    # IMPORTANT: Valid ONLY for 80x200 input and ResNet encoder.
    # ResNet output is [Batch, 64, H/32, W/32].
    # H=80 -> 2. W=200 -> 6. Result: 64 * 2 * 6 = 768.
    output_dim: 768  
  
  # --- 3. Projector (Optional) ---
  projector_type: null # Not needed if Head can take Adapter output directly
  
  # --- 4. Sequence Model (Not used for Classification) ---
  sequence_model_type: null
    
  # --- 5. Head (Vector -> Class Logits) ---
  head_type: "classification"
  head_config:
    num_classes: 100 # Example: 10 digit classes
    d_model: 768 # Must match Adapter output dimension
    head_hidden_dim: 256 # Intermediate dense layer size
    pooling_type: "mean" # Ignored if input is already flat/2D, but good to keep
  
  # Global Params
  d_model: 768 # Matches pipeline width at head input
  d_vocab: 100 # Roughly matches num_classes
  loss_type: "cross_entropy"

training_config:
  batch_size: 32
  epochs: 20
  learning_rate: 0.0001
  optimizer_type: "adamw" # adam, adamw, sgd
  weight_decay: 0.01
  grad_clip_norm: 1.0
  accumulate_grad_batches: 1
  
  # Checkpointing & Logging
  checkpoint_dir: "experiments/classification/resnet/checkpoints"
  save_every_n_epochs: 1
  monitor_metric: "val_acc" # Monitor accuracy for classification
  wandb_project: "captcha-ocr"
  log_every_n_steps: 10
  
  # Hardware & Data
  device: "cuda"
  num_workers: 4
  mixed_precision: false
  #val_split: 0.1 # necessary only if train_metadata_path and val_metadata_path are not provided
  shuffle_train: true
