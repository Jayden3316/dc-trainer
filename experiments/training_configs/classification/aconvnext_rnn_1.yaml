experiment_name: "classification_sequence_rnn"
seed: 42
train_metadata_path: "dataset_train/dataset/metadata.json"
val_metadata_path: "dataset_val/dataset/metadata.json"

dataset_config:
  width: 200
  height: 80
  width_divisor: 8
  width_bias: 0
  resize_mode: "variable"
  image_ext: "png"
  
  max_fonts_per_family: 1 
  random_capitalize: False
  noise_bg_density: 0
  add_noise_dots: False
  add_noise_curve: False
  extra_spacing: 0
  spacing_jitter: 0
  word_space_probability: 0
  word_offset_dx: 0.0

model_config:
  pipeline_type: "sequence_classification"
  task_type: "classification"
  
  # 1. Encoder
  encoder_type: "convnext"
  encoder_config:
    dims: [32, 64, 128, 256]
    stage_block_counts: [2, 2, 6, 2]
    strides: [(2, 1), (2, 1), (2, 1), (2, 1)]
  # 2. Adapter (Spatial -> Sequence)
  encoder_adapter_type: "vertical_feature"
  encoder_adapter_config:
    output_dim: 1024 # Matches d_model
  
  # 3. Projector (Optional)
  projector_type: "linear"
  projector_config:
    output_dim: 256

  # 4. Sequence Model
  sequence_model_type: "rnn"
  sequence_model_config:
    hidden_size: 256
    num_layers: 2
    dropout: 0.1
    bidirectional: False
    
  # 5. Sequence Adapter (Sequence -> Vector)
  sequence_adapter_type: "sequence_pool"
  sequence_adapter_config:
    pool_type: "last" # Use last hidden state for RNN
    
  # 6. Head
  head_type: "classification"
  head_config:
    num_classes: 100
    d_model: 256
    head_hidden_dim: 128
    
  # Global
  d_model: 256
  d_vocab: 100
  loss_type: "cross_entropy"

training_config:
  batch_size: 32
  epochs: 50
  learning_rate: 0.0001
  optimizer_type: "adamw"
  weight_decay: 0.01
  grad_clip_norm: 1.0
  accumulate_grad_batches: 1
  
  checkpoint_dir: "experiments/classification/aconvnext_rnn/checkpoints"
  save_every_n_epochs: 1
  monitor_metric: "val_acc"
  wandb_project: "captcha-ocr"
  log_every_n_steps: 10
  
  device: "cuda"
  num_workers: 4
  mixed_precision: false
  shuffle_train: true
